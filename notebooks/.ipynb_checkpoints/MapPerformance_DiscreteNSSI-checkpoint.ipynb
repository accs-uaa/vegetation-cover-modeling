{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for file manipulation, data manipulation, and plotting\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plot\n",
    "# Import module for altering output display\n",
    "from IPython.display import clear_output\n",
    "# Import modules for preprocessing, model selection, linear regression, and performance from Scikit Learn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input file\n",
    "input_file = 'E:/VegetationEcology/Data_Harmonization/Supplemental/discrete_vaccinium_vitisidaea.csv'\n",
    "# Define output metrics file\n",
    "metrics_file = 'E:/VegetationEcology/Data_Harmonization/Supplemental/discrete_vaccinium_vitisidaea_metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate pseudo r-squared and RMSE for the composited prediction\n",
    "def calculatePerformance(test, cover, prediction):\n",
    "    # Define the true values and the predicted values for the response variable\n",
    "    y_test = test[cover[0]]\n",
    "    y_prediction = test[prediction[0]]\n",
    "    # Calculate pseudo r-squared\n",
    "    r_score = r2_score(y_test, y_prediction, sample_weight=None, multioutput='uniform_average')\n",
    "    # Calculate error\n",
    "    mae = mean_absolute_error(y_test, y_prediction)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_prediction))\n",
    "    # Return performance metrics\n",
    "    return r_score, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to conduct a train test iteration\n",
    "def trainTest(X_array, y):\n",
    "    # Split the data into a train and test partitions\n",
    "    stratify = aim_data[strata[0]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_array,\n",
    "                                                        y,\n",
    "                                                        test_size = 0.3,\n",
    "                                                        train_size = 0.7,\n",
    "                                                        random_state = None,\n",
    "                                                        shuffle = True,\n",
    "                                                        stratify = stratify)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    # Fit and predict a linear regression\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(X_train, y_train)\n",
    "    prediction = regression.predict(X_test)\n",
    "    # Concatenate the formatted labels to the data frame\n",
    "    result = pd.concat([pd.DataFrame(y_test), pd.DataFrame(prediction)], axis=1)\n",
    "    result = result.rename(index=int, columns={0: 'prediction'})\n",
    "    r2, mae, mse = calculatePerformance(result, cover, response)\n",
    "    return r2, mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "cover = ['cover']\n",
    "discrete = ['NSSI']\n",
    "strata = ['strata']\n",
    "predictors = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "response = ['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame of input data\n",
    "input_data = pd.read_csv(input_file)\n",
    "# Convert values to floats\n",
    "input_data[cover[0]] = input_data[cover[0]].astype(float)\n",
    "input_data = shuffle(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset input data to AIM data\n",
    "aim_data = input_data[input_data['project'] == 'AIM NPR-A']\n",
    "aim_data = aim_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y data\n",
    "X = aim_data[discrete[0]]\n",
    "y = aim_data[cover[0]]\n",
    "# Convert the X data to numpy array\n",
    "X = np.asarray(X)\n",
    "X = np.reshape(X, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='ignore', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a one-hot encoder to the discrete map classes\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X data using one-hot encoder\n",
    "X_array = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model train-test iteration 34 out of 100 completed...\n"
     ]
    }
   ],
   "source": [
    "# Conduct 100 train test iterations\n",
    "r2_list = []\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "i = 1\n",
    "while i < 101:\n",
    "    # Set output display to show one message with replacement\n",
    "    clear_output(wait=True)\n",
    "    # Run train test iteration\n",
    "    r2, mae, mse = trainTest(X_array, y)\n",
    "    # Append performance metrics to list\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    mse_list.append(mse)\n",
    "    # Print status\n",
    "    print('Model train-test iteration ' + str(i) + ' out of 100 completed...')\n",
    "    # Increase counter\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation\n",
    "r2_mean = np.mean(r2_list)\n",
    "mae_mean = np.mean(mae_list)\n",
    "mse_mean = np.mean(mse_list)\n",
    "r2_sd = np.std(r2_list)\n",
    "mae_sd = np.std(mae_list)\n",
    "mse_sd = np.std(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export threshold and performance metrics as a table\n",
    "metrics_dataframe = pd.DataFrame({'r2':r2_list,\n",
    "                                  'mae':mae_list,\n",
    "                                  'mse':mse_list})\n",
    "metrics_dataframe.to_csv(metrics_file, header=True, index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report mean and standard deviation r2\n",
    "print(r2_mean)\n",
    "print(r2_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
