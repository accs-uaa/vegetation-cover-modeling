{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delineate Sample Representation Area\n",
    "\n",
    "**Written by Timm Nawrocki**\n",
    "\n",
    "*Last updated Saturday, October 20, 2018*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---------------------------------------------------------------------------\n",
    "# Delineate Prediction Area\n",
    "# Author: Timm Nawrocki, Alaska Center for Conservation Science\n",
    "# Created on: 2018-10-20\n",
    "# Usage: Must be executed as a Jupyter Notebook in an Anaconda 3 installation. Created using Anaconda 3 version 5.2.0.\n",
    "# Description: \"Delineate Prediction Area\" predicts a one-class outlier detection model to watershed data to determine the sample coverage of the watershed.\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Define model folder\n",
    "model_folder = 'K:/VegetationEcology/Data_Harmonization/Project_GIS/Data_Output/modelResults/area_prediction/'\n",
    "# Define input data folder\n",
    "watershed_folder = 'K:/VegetationEcology/Data_Harmonization/Project_GIS/Data_Output/watershedData/'\n",
    "# Define output folder\n",
    "output_folder = 'K:/VegetationEcology/Data_Harmonization/Project_GIS/Data_Output/predictions/study_area/'\n",
    "# Define subset for parallel computing\n",
    "subset = list(range(1, 2))\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_all = ['compoundTopographic', 'dateFreeze_2000s', 'dateThaw_2000s', 'elevation', 'floodplainsDist', 'growingSeason_2000s', 'heatLoad', 'integratedMoisture', 'precipAnnual_2000s', 'roughness', 'siteExposure', 'slope', 'streamLargeDist', 'streamSmallDist', 'summerWarmth_2000s', 'surfaceArea', 'surfaceRelief', 'aspect', 'may_1_ultraBlue', 'may_2_blue', 'may_3_green', 'may_4_red', 'may_5_nearInfrared', 'may_6_shortInfrared1', 'may_7_shortInfrared2', 'may_evi2', 'may_nbr', 'may_ndmi', 'may_ndsi', 'may_ndvi', 'may_ndwi', 'june_1_ultraBlue', 'june_2_blue', 'june_3_green', 'june_4_red', 'june_5_nearInfrared', 'june_6_shortInfrared1', 'june_7_shortInfrared2', 'june_evi2', 'june_nbr', 'june_ndmi', 'june_ndsi', 'june_ndvi', 'june_ndwi', 'july_1_ultraBlue', 'july_2_blue', 'july_3_green', 'july_4_red', 'july_5_nearInfrared', 'july_6_shortInfrared1', 'july_7_shortInfrared2', 'july_evi2', 'july_nbr', 'july_ndmi', 'july_ndsi', 'july_ndvi', 'july_ndwi', 'august_1_ultraBlue', 'august_2_blue', 'august_3_green', 'august_4_red', 'august_5_nearInfrared', 'august_6_shortInfrared1', 'august_7_shortInfrared2', 'august_evi2', 'august_nbr', 'august_ndmi', 'august_ndsi', 'august_ndvi', 'august_ndwi', 'september_1_ultraBlue', 'september_2_blue', 'september_3_green', 'september_4_red', 'september_5_nearInfrared', 'september_6_shortInfrared1', 'september_7_shortInfrared2', 'september_evi2', 'september_nbr', 'september_ndmi', 'september_ndsi', 'september_ndvi', 'september_ndwi']\n",
    "coordinates = ['POINT_X', 'POINT_Y']\n",
    "outlier = ['outlier']\n",
    "output_columns = coordinates + outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for file manipulation, data manipulation, and plotting\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plot\n",
    "# Import module for altering output display\n",
    "from IPython.display import clear_output\n",
    "# Import modules for feature pre-processing and novelty detection from Scikit Learn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model files\n",
    "scaler_file = os.path.join(model_folder, 'scaler.joblib')\n",
    "outlier_file = os.path.join(model_folder, 'outlier_detector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaler and the outlier detector\n",
    "scaler = joblib.load(scaler_file)\n",
    "outlier_detector = joblib.load(outlier_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1908010402.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of input files for the prediction step\n",
    "input_files = os.listdir(watershed_folder)\n",
    "# Define the subset list of files\n",
    "subset_files = [input_files[n] for n in subset]\n",
    "subset_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to predict outliers\n",
    "def detectOutliers(input_data, predictors, scaler, outlier_detector):\n",
    "    # Create X data from the predictors\n",
    "    X = input_data[predictors]\n",
    "    # Scale the X data\n",
    "    X_scaled = scaler.transform(X)\n",
    "    # Predict outliers in the scaled X data\n",
    "    prediction = outlier_detector.predict(X_scaled)\n",
    "    # Concatenate predicted values to input data frame\n",
    "    output_data = pd.concat([input_data, pd.DataFrame(prediction)], axis=1)\n",
    "    output_data = output_data.rename(index=int, columns={0: 'outlier'})\n",
    "    # Return the output data\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction iteration 2 out of 2 complete...\n"
     ]
    }
   ],
   "source": [
    "# Loop through the prediction function for all input files\n",
    "for watershed_data in subset_files:\n",
    "    # Set output display to show one message with replacement\n",
    "    clear_output(wait=True)\n",
    "    # Identify input and output csv files\n",
    "    predict_csv = os.path.join(watershed_folder, watershed_data)\n",
    "    output_csv = os.path.join(output_folder, watershed_data)\n",
    "    # Read input data to data frame\n",
    "    predict_data = pd.read_csv(predict_csv)\n",
    "    predict_data[predictor_all + coordinates] = predict_data[predictor_all + coordinates].astype(float)\n",
    "    # Predict outliers in the data frame\n",
    "    output_data = detectOutliers(predict_data, predictor_all, scaler, outlier_detector)\n",
    "    # Export prediction to csv\n",
    "    output_data = output_data[output_columns]\n",
    "    output_data.to_csv(output_csv, header=True, index=False, sep=',', encoding='utf-8')\n",
    "    # Print loop status\n",
    "    print('Prediction iteration ' + str(input_files.index(watershed_data) + 1) + ' out of ' + str(len(input_files)) + ' complete...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
