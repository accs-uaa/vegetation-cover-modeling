{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---------------------------------------------------------------------------\n",
    "# Classifiers Predict\n",
    "# Author: Timm Nawrocki, Alaska Center for Conservation Science\n",
    "# Created on: 2018-08-18\n",
    "# Usage: Must be executed as a Jupyter Notebook in an Anaconda 3 installation on a Google Cloud virtual machine with 64 vCPUs and 57.6 GB of CPU memory with an Ubuntu operating system (18.04 LTS).\n",
    "# Description: \"Classifiers Predict\" imports three classifiers trained in an external script and uses them to create a composite prediction for each watershed in a set of watershed input files.\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script runs the model prediction steps for all watersheds in a set of watershed input files. The script is formatted as a Jupyter Notebook and is intended to be run on a Google Cloud virtual machine with 64 vCPUs and 57.6 GB of CPU memory with an Ubuntu operating system (18.04 LTS). The Random Forest classifier in this script is set to use 16 cores and may work inefficiently or not at all on a machine that has less than 64 cores. For information on generating inputs for this script or on setting up Google Cloud virtual machines, see the [project readme](https://github.com/accs-uaa/vegetation-cover-modeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "print(\"All modules successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user input variables\n",
    "print('Enter root directory:')\n",
    "root_folder = input()\n",
    "print('Enter name of output folder:')\n",
    "output_folder = input()\n",
    "print('Enter name of predict folder:')\n",
    "prediction_folder = input()\n",
    "print('All user-defined variables input.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable sets\n",
    "predictor_variables = ['compoundTopographic', 'dateFreeze_2000s', 'dateThaw_2000s', 'elevation', 'floodplainsDist', 'growingSeason_2000s', 'heatLoad', 'integratedMoisture', 'precipAnnual_2000s', 'roughness', 'siteExposure', 'slope', 'streamLargeDist', 'streamSmallDist', 'summerWarmth_2000s', 'surfaceArea', 'surfaceRelief', 'aspect', 'l8_evi2', 'l8_green', 'l8_nbr', 'l8_ndmi', 'l8_ndsi', 'l8_ndvi', 'l8_ndwi', 'l8_nearInfrared', 'l8_red', 'l8_shortInfrared1', 'l8_shortInfrared2', 'l8_ultrablue', 'l8_blue']\n",
    "coordinates = ['POINT_X', 'POINT_Y']\n",
    "output_variables = coordinates + ['predict_0', 'predict_10', 'predict_25', 'classification']\n",
    "print('Variable sets loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read threshold values from text file\n",
    "def readThreshold(inFile):\n",
    "    threshold_reader = open(inFile, \"r\")\n",
    "    threshold = threshold_reader.readlines()\n",
    "    threshold_reader.close()\n",
    "    outThreshold = int(threshold[0])\n",
    "    return outThreshold\n",
    "\n",
    "print('Function \"readThreshold\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to use a random forest classifier to make a probability prediction, threshold the prediction, and output to dataframe\n",
    "def predictModel(inModel, inThreshold, inDataframe, variable):\n",
    "    prediction = inModel.predict_proba(inDataframe[predictor_variables])\n",
    "    predict_index = [int((p[1] * 1000) + 0.5) for p in prediction]\n",
    "    predict_index = np.asarray(predict_index)\n",
    "    outThresholded = np.zeros(predict_index.shape)\n",
    "    outThresholded[predict_index > inThreshold] = 1\n",
    "    inDataframe = pd.concat([inDataframe, pd.DataFrame(outThresholded)], axis=1)\n",
    "    inDataframe = inDataframe.rename(index=int, columns={0: variable})\n",
    "    return inDataframe\n",
    "\n",
    "print('Function \"predictModel\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create composite classification\n",
    "def compositeClassification (row):\n",
    "    if row['predict_0'] == 0:\n",
    "        return 0\n",
    "    elif row['predict_0'] == 1 and row['predict_10'] == 0:\n",
    "        return 1\n",
    "    elif row['predict_0'] == 1 and row['predict_10'] == 1 and row['predict_25'] == 0:\n",
    "        return 2\n",
    "    elif row['predict_0'] == 1 and row['predict_10'] == 1 and row['predict_25'] == 1:\n",
    "        return 3\n",
    "\n",
    "print('Function \"compositeClassification\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to predict and export a predict dataset using input classifier models and thresholds\t\n",
    "def compositeModel(inModel_0, inModel_10, inModel_25, inThreshold_0, inThreshold_10, inThreshold_25, inData, outCSV):\n",
    "    # Convert the input data to a data frame\n",
    "    predict_df = convertFeature(inData)\n",
    "    # Use the 0 classifier to make binary prediction and append results to predict dataframe\n",
    "    predict_df = predictModel(inModel_0, inThreshold_0, predict_df, \"predict_0\")\n",
    "    # Use the 10 classifier to make binary prediction and append results to predict dataframe\n",
    "    predict_df = predictModel(inModel_10, inThreshold_10, predict_df, \"predict_10\")\n",
    "    # Use the 25 classifier to make binary prediction and append results to predict dataframe\n",
    "    predict_df = predictModel(inModel_25, inThreshold_25, predict_df, \"predict_25\")\n",
    "    # Apply composite classification function to the predictions in the test dataframe\n",
    "    predict_df['classification'] = predict_df.apply(lambda row: compositeClassification(row), axis=1)\n",
    "    output_df = predict_df[output_variables]\n",
    "    # Export the output dataframe to the output csv\n",
    "    output_df.to_csv(outCSV, header=True, index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "print('Function \"compositeModel\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model the zero, ten, and twentyfive classifiers\n",
    "model_0 = joblib.load(os.path.join(output_folder, 'classifier_0.joblib'))\n",
    "model_10 = joblib.load(os.path.join(output_folder, 'classifier_10.joblib'))\n",
    "model_25 = joblib.load(os.path.join(output_folder, 'classifier_25.joblib'))\n",
    "print(model_0)\n",
    "print(model_10)\n",
    "print(model_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read thresholds from text files in the workspace folder and store as variables\n",
    "threshold_0 = readThreshold(os.path.join(output_folder, 'threshold_0.txt'))\n",
    "threshold_10 = readThreshold(os.path.join(output_folder, 'threshold_10.txt'))\n",
    "threshold_25 = readThreshold(os.path.join(output_folder, 'threshold_25.txt'))\n",
    "print('Threshold 0: ' + str(threshold_0))\n",
    "print('Threshold 10: ' + str(threshold_10))\n",
    "print('Threshold 25: ' + str(threshold_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of input files for the prediction step\n",
    "input_files = os.listdir(os.path.join(root_folder, 'watershedData'))\n",
    "print(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the prediction function for all input files\n",
    "for watershed_data in input_files:\n",
    "    predict_csv = os.path.join(os.path.join(root_folder, 'watershedData'), watershed_data)\n",
    "    output_csv = os.path.join(prediction_folder, watershed_data)\n",
    "    predict_df = pd.read_csv(predict_csv)\n",
    "    predict_df[predictor_variables] = predict_df[predictor_variables].astype(int)\n",
    "    compositeModel(model_0, model_10, model_25, threshold_0, threshold_10, threshold_25, predict_df, output_csv)\n",
    "    print('Prediction iteration ' + str(input_files.index(watershed_data) + 1) + ' out of ' + str(len(input_files)) + ' complete...')\n",
    "print('All predictions complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
