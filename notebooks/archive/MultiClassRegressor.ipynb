{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules successfully imported.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import ARDRegression, BayesianRidge\n",
    "from collections import Counter\n",
    "print('All modules successfully imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable sets loaded.\n"
     ]
    }
   ],
   "source": [
    "# Define variable sets\n",
    "predictor_metrics = ['compoundTopographic', 'dateFreeze_2000s', 'dateThaw_2000s', 'elevation', 'floodplainsDist', 'growingSeason_2000s', 'heatLoad', 'integratedMoisture', 'precipAnnual_2000s', 'roughness', 'siteExposure', 'slope', 'streamLargeDist', 'streamSmallDist', 'summerWarmth_2000s', 'surfaceArea', 'surfaceRelief', 'aspect', 'may_2_blue', 'may_evi2', 'may_nbr', 'may_ndmi', 'may_ndsi', 'may_ndvi', 'may_ndwi', 'june_2_blue', 'june_evi2', 'june_nbr', 'june_ndmi', 'june_ndsi', 'june_ndvi', 'june_ndwi', 'july_2_blue', 'july_evi2', 'july_nbr', 'july_ndmi', 'july_ndsi', 'july_ndvi', 'july_ndwi', 'august_2_blue', 'august_evi2', 'august_nbr', 'august_ndmi', 'august_ndsi', 'august_ndvi', 'august_ndwi', 'september_2_blue', 'september_evi2', 'september_nbr', 'september_ndmi', 'september_ndsi', 'september_ndvi', 'september_ndwi']\n",
    "zero_variable = ['zero']\n",
    "cover = ['cover']\n",
    "coverLog = ['coverLog']\n",
    "strata = ['strata']\n",
    "retain_variables = ['project', 'siteID', 'siteCode', 'methodSurvey', 'methodCover']\n",
    "coordinates = ['POINT_X', 'POINT_Y']\n",
    "all_variables = retain_variables + coordinates + predictor_metrics + zero_variable + strata + cover + coverLog\n",
    "scale_variables = predictor_metrics\n",
    "print('Variable sets loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input data\n",
    "input_file = 'E:/VegetationEcology/Data_Harmonization/Project_GIS/Data_Output/testRegression/betula_nana_mod.csv'\n",
    "# Create data frame of input data\n",
    "input_data = pd.read_csv(input_file)\n",
    "# Convert values to floats\n",
    "input_data[predictor_metrics + cover + coordinates] = input_data[predictor_metrics + cover + coordinates].astype(float)\n",
    "# Convert values to integers\n",
    "input_data[strata + zero_variable + coverLog] = input_data[strata + zero_variable + coverLog].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test splits\n",
    "X = input_data[all_variables]\n",
    "y = input_data[coverLog[0]]\n",
    "stratify = input_data[coverLog[0]]\n",
    "all_train, all_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, train_size = 0.7, random_state = None, shuffle = True, stratify = stratify)\n",
    "all_train = all_train.reset_index()\n",
    "all_test = all_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standard scaler to set mean = 0 and scale unit variance (scale all variables to Gaussian distribution)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_train[predictor_metrics])\n",
    "# Scale the train data\n",
    "train_scaled = scaler.transform(all_train[predictor_metrics])\n",
    "all_train.drop(columns=predictor_metrics)\n",
    "all_train = pd.concat([all_train, pd.DataFrame(data=train_scaled, columns=predictor_metrics)], axis=1)\n",
    "# Scale the test data\n",
    "test_scaled = scaler.transform(all_test[predictor_metrics])\n",
    "all_test.drop(columns=predictor_metrics)\n",
    "all_test = pd.concat([all_test, pd.DataFrame(data=test_scaled, columns=predictor_metrics)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X_train = all_train[predictor_metrics]\n",
    "y_train = all_train[coverLog[0]]\n",
    "X_test = all_test[predictor_metrics]\n",
    "y_test = all_test[coverLog[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest model\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', max_features = 'log2', bootstrap = True, oob_score = False, n_jobs = 1, class_weight = 'balanced')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict class probabilities\n",
    "test_prediction = classifier.predict_proba(X_test)\n",
    "# Concatenate predicted values to test data frame\n",
    "all_test = pd.concat([all_test, pd.DataFrame(test_prediction)], axis=1)\n",
    "all_test = all_test.rename(index=int, columns={0: 'predict'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export predicted data\n",
    "output_file = 'E:/VegetationEcology/Data_Harmonization/Project_GIS/Data_Output/testRegression/predicted.csv'\n",
    "all_test.to_csv(output_file, header=True, index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
